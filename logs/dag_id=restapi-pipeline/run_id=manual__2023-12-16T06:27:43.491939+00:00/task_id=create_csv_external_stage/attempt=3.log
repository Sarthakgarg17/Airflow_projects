[2023-12-16T06:28:29.979+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: restapi-pipeline.create_csv_external_stage manual__2023-12-16T06:27:43.491939+00:00 [queued]>
[2023-12-16T06:28:29.983+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: restapi-pipeline.create_csv_external_stage manual__2023-12-16T06:27:43.491939+00:00 [queued]>
[2023-12-16T06:28:29.983+0000] {taskinstance.py:1361} INFO - Starting attempt 3 of 3
[2023-12-16T06:28:29.989+0000] {taskinstance.py:1382} INFO - Executing <Task(SnowflakeOperator): create_csv_external_stage> on 2023-12-16 06:27:43.491939+00:00
[2023-12-16T06:28:29.992+0000] {standard_task_runner.py:57} INFO - Started process 7282 to run task
[2023-12-16T06:28:29.994+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'restapi-pipeline', 'create_csv_external_stage', 'manual__2023-12-16T06:27:43.491939+00:00', '--job-id', '271', '--raw', '--subdir', 'DAGS_FOLDER/restapi.py', '--cfg-path', '/tmp/tmplpdw484s']
[2023-12-16T06:28:29.996+0000] {standard_task_runner.py:85} INFO - Job 271: Subtask create_csv_external_stage
[2023-12-16T06:28:30.018+0000] {task_command.py:416} INFO - Running <TaskInstance: restapi-pipeline.create_csv_external_stage manual__2023-12-16T06:27:43.491939+00:00 [running]> on host e65e9d73b232
[2023-12-16T06:28:30.085+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='sarthak' AIRFLOW_CTX_DAG_ID='restapi-pipeline' AIRFLOW_CTX_TASK_ID='create_csv_external_stage' AIRFLOW_CTX_EXECUTION_DATE='2023-12-16T06:27:43.491939+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-12-16T06:27:43.491939+00:00'
[2023-12-16T06:28:30.086+0000] {sql.py:274} INFO - Executing: 
CREATE OR REPLACE STAGE csv_s3_stage
URL='s3://my-random-bucket-002/coin-price-csv'
CREDENTIALS=(AWS_KEY_ID='AKIA4SXCAFHSOCMPU7LX' AWS_SECRET_KEY='DYlOTEHyogLcr0JylaJV8RdHRhCbUw9GFRzT/aEO')
DIRECTORY = (ENABLE = TRUE)
FILE_FORMAT = my_csv_format;
[2023-12-16T06:28:30.095+0000] {base.py:73} INFO - Using connection ID 'snowflake_default' for task execution.
[2023-12-16T06:28:30.101+0000] {base.py:73} INFO - Using connection ID 'snowflake_default' for task execution.
[2023-12-16T06:28:30.101+0000] {connection.py:334} INFO - Snowflake Connector for Python Version: 3.3.1, Python Version: 3.8.18, Platform: Linux-6.5.11-linuxkit-aarch64-with-glibc2.17
[2023-12-16T06:28:30.102+0000] {connection.py:1103} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-12-16T06:28:30.102+0000] {connection.py:1121} INFO - Setting use_openssl_only mode to False
[2023-12-16T06:28:30.881+0000] {cursor.py:833} INFO - query: [ALTER SESSION SET autocommit=False]
[2023-12-16T06:28:31.034+0000] {cursor.py:846} INFO - query execution done
[2023-12-16T06:28:31.035+0000] {cursor.py:988} INFO - Number of results in first chunk: 1
[2023-12-16T06:28:31.036+0000] {sql.py:418} INFO - Running statement: CREATE OR REPLACE STAGE csv_s3_stage
URL='s3://my-random-bucket-002/coin-price-csv'
CREDENTIALS=(AWS_KEY_ID='AKIA4SXCAFHSOCMPU7LX' AWS_SECRET_KEY='DYlOTEHyogLcr0JylaJV8RdHRhCbUw9GFRzT/aEO')
DIRECTORY = (ENABLE = TRUE)
FILE_FORMAT = my_csv_format;, parameters: None
[2023-12-16T06:28:31.037+0000] {cursor.py:833} INFO - query: [CREATE OR REPLACE STAGE csv_s3_stage URL='s3://my-random-bucket-002/coin-price-c...]
[2023-12-16T06:28:32.115+0000] {cursor.py:846} INFO - query execution done
[2023-12-16T06:28:32.122+0000] {connection.py:677} INFO - closed
[2023-12-16T06:28:32.183+0000] {connection.py:683} INFO - No async queries seem to be running, deleting session
[2023-12-16T06:28:32.253+0000] {taskinstance.py:1937} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/common/sql/operators/sql.py", line 280, in execute
    output = hook.run(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/snowflake/hooks/snowflake.py", line 388, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/common/sql/hooks/sql.py", line 423, in _run_command
    cur.execute(sql_statement)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/cursor.py", line 937, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.8/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 091003 (22000): 01b10564-3200-f72f-0007-44420002502a: Failure using stage area. Cause: [The AWS Access Key Id you provided is not valid.]
[2023-12-16T06:28:32.270+0000] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=restapi-pipeline, task_id=create_csv_external_stage, execution_date=20231216T062743, start_date=20231216T062829, end_date=20231216T062832
[2023-12-16T06:28:32.348+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 271 for task create_csv_external_stage (091003 (22000): 01b10564-3200-f72f-0007-44420002502a: Failure using stage area. Cause: [The AWS Access Key Id you provided is not valid.]; 7282)
[2023-12-16T06:28:32.382+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2023-12-16T06:28:32.394+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
